# Copy as .env file and fill your values below
# Run ./update_dotenv_example.sh to update .env-example from your .env file.

# --- General Application Configuration ---
# Name of your Flask application
FLASK_APP_NAME="AI_Assistant_RAG"

# Host and Port for the Flask/Gunicorn server
HOST="0.0.0.0"
PORT=3010

# Enable/Disable Flask debug mode (True/False or 1/0)
FLASK_DEBUG=True

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL="DEBUG"

# Directory for temporary document storage during upload
DOCUMENT_STORAGE_DIRECTORY="/app/data"

# --- Google Cloud & Vertex AI Configuration ---
# Choose Model Backend: 0 -> ML Dev, 1 -> Vertex
# RAG Engine only works with Vertex, so this should be 1.
GOOGLE_GENAI_USE_VERTEXAI=1

# Your Google Cloud Project ID
GOOGLE_CLOUD_PROJECT="api-project-507154614599"

# Your Google Cloud/Vertex AI region (e.g., us-central1)
GOOGLE_CLOUD_LOCATION="us-central1"

# Existing RAG Corpus in Vertex AI to be used by the RAG agent
# Format: projects/<PROJECT_NUMBER>/locations/<LOCATION>/ragCorpora/<CORPUS_ID>
RAG_CORPUS='projects/507154614599/locations/us-central1/ragCorpora/3170534137668829184'

# Staging bucket for document uploads to Vertex AI RAG Corpus
# Format: gs://your-bucket-name
STAGING_BUCKET='gs://ai-assistant-staging-507154614599'

# Agent Engine ID in the following format:
# projects/<PROJECT_NUMBER>/locations/<LOCATION>/reasoningEngines/<AGENT_ENGINE_ID>
# This is the ID of your deployed Agent Engine.
AGENT_ENGINE_ID='projects/507154614599/locations/us-central1/reasoningEngines/8737660576261472256'
OPENAPI_AGENT_ENGINE_ID='projects/507154614599/locations/us-central1/reasoningEngines/6779439163285438464'

# --- Large Language Model (LLM) Configuration ---
# Model name for general knowledge and orchestration (e.g., gemini-2.0-flash-001)
LLM_MODEL_NAME="gemini-2.0-flash-001"

# LLM creativity/randomness (0.0 for deterministic, 1.0 for highly creative)
LLM_TEMPERATURE=0.2

MODEL_MODE="adk_agent_engine"

# --- Document Processing Configuration (for RAG corpus upload) ---
# Size of document chunks for RAG (in tokens)
RAG_CHUNK_SIZE=500

# Overlap between document chunks for RAG (in tokens)
RAG_CHUNK_OVERLAP=50

# --- Gunicorn Web Server Configuration ---
# Timeout for Gunicorn workers (seconds)
GUNICORN_TIMEOUT=120

# Number of Gunicorn worker processes
GUNICORN_WORKERS=2

# --- Deprecated/Unused Variables (Keeping for reference if needed later) ---
# ML Dev backend config (Not used when GOOGLE_GENAI_USE_VERTEXAI=1)
# GOOGLE_API_KEY=YOUR_VALUE_HERE

# GCS Bucket for raw document storage (Not used in current RAG flow)
# GCS_BUCKET_NAME='ai-assistant-docs-507154614599'